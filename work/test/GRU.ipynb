{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3461,
     "status": "ok",
     "timestamp": 1600875387259,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "mae58AtyV1SZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30796,
     "status": "ok",
     "timestamp": 1600875414602,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "FhFL3a9pV-R8",
    "outputId": "d15ac253-b8b4-479c-b459-d26eae0a542b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xp2R2YzsV1Sq"
   },
   "source": [
    "# 先行研究"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c31dYXj7V1Sx"
   },
   "source": [
    "## 発話エンコーダ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QL-v4GOVV1S1"
   },
   "outputs": [],
   "source": [
    "utter_embedding = tf.keras.layers.Embedding(1000, 300)\n",
    "utter_gru = tf.keras.layers.GRU(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMeBIG2NV1S6"
   },
   "source": [
    "## 文脈エンコーダ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "peVi8D3CV1S7"
   },
   "outputs": [],
   "source": [
    "context_gru = tf.keras.layers.GRU(513)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_rjoQ6xV1S-"
   },
   "source": [
    "## 対話行為エンコーダ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogVUEn_PV1S_"
   },
   "outputs": [],
   "source": [
    "dialog_embedding = tf.keras.layers.Embedding(1000, 100)\n",
    "dialog_gru = tf.keras.layers.GRU(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CzdTutbnV1TE"
   },
   "source": [
    "## 分類器設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNOOkt7uV1TO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rfOtKArV1TR"
   },
   "source": [
    "## 損失関数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEueQydZV1TS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tfzP-i_TV1TZ"
   },
   "source": [
    "## 最適化関数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptKjxj7RV1Tb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6b1w5wFoV1To"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEqDAGOlV1Ty"
   },
   "source": [
    "## 実行(前処理)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQEkd7w0V1T3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ggGk_kQzV1T6"
   },
   "source": [
    "## filepath(colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 922,
     "status": "ok",
     "timestamp": 1600879349516,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "977FNVKhV1T8"
   },
   "outputs": [],
   "source": [
    "#train_data = \"drive/My Drive/研究/swda_data/train_set.txt\"\n",
    "#test_data = \"../Switchboard-Corpus/swda_data/test_set.txt\"\n",
    "#val_data = \"drive/My Drive/研究/swda_data/val_set.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filepath(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"../Switchboard-Corpus/swda_data/train_set.txt\"\n",
    "test_data = \"../Switchboard-Corpus/swda_data/test_set.txt\"\n",
    "val_data = \"../Switchboard-Corpus/swda_data/val_set.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "TAKE_SIZE = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファイル取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1671,
     "status": "ok",
     "timestamp": 1600875601342,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "rl2VC27AV1UB"
   },
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "f = open(train_data, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    train_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "f = open(val_data, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    val_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "f = open(val_data, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    test_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1600877035142,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "MqDzgatLsgMV"
   },
   "source": [
    "## 発話者,発話,発話ラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1208,
     "status": "ok",
     "timestamp": 1600875601344,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "yQdZAZTnV1Ub",
    "outputId": "722c170c-f08e-496a-82a9-c92b98784bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "utter_user = []\n",
    "utter = []\n",
    "utter_label = []\n",
    "datasets = [train_dataset, val_dataset, test_dataset]\n",
    "\n",
    "for d in datasets:\n",
    "    for j in d:\n",
    "        for i,v in enumerate(j.split(\"|\")):\n",
    "            if i == 0:\n",
    "                utter_user.append(v)\n",
    "            elif i==1:\n",
    "                utter.append(v)\n",
    "            else:\n",
    "                utter_label.append(v)\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set(utter_label)\n",
    "utter_labels = []\n",
    "for i in utter_label:\n",
    "    for j,v in enumerate(labels):\n",
    "        if i == v:\n",
    "            utter_labels.append(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 20, 0, 30, 11, 5, 38, 5, 5, 6]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198934, 198934, 198934)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utter_label),len(utter),len(utter_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1600877130288,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "HFnggyYttizg"
   },
   "source": [
    "## データセット化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1978,
     "status": "ok",
     "timestamp": 1600881987551,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "RgrZO1b6oPAt"
   },
   "outputs": [],
   "source": [
    "train_datasets = tf.data.Dataset.from_tensor_slices((utter, utter_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Okay.', shape=(), dtype=string)\n",
      "tf.Tensor(35, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "text, label = next(iter(train_datasets.take(1)))\n",
    "print(text)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Okay.'>, <tf.Tensor: shape=(), dtype=int32, numpy=35>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'So, What kind of experience do you, do you have, then with child care?'>, <tf.Tensor: shape=(), dtype=int32, numpy=20>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'I guess, I think, uh, I wonder if that worked.'>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Does it say something?'>, <tf.Tensor: shape=(), dtype=int32, numpy=30>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'I think it usually does.'>, <tf.Tensor: shape=(), dtype=int32, numpy=11>)\n"
     ]
    }
   ],
   "source": [
    "lists = []\n",
    "for (i, ex) in enumerate(train_datasets.take(5)):\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1653,
     "status": "ok",
     "timestamp": 1600881065641,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "Ajtfr6m-t3mP"
   },
   "source": [
    "## トークナイザー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20359,
     "status": "ok",
     "timestamp": 1600882009164,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "Pt1ZNG2sV1Un"
   },
   "outputs": [],
   "source": [
    "## ボキャブラリーリスト\n",
    "vocabulary_set = set()\n",
    "## トークナイザー\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "## 分かち書き\n",
    "for text_tensor,_ in train_datasets:\n",
    "    some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "    vocabulary_set.update(some_tokens)\n",
    "    \n",
    "## ボキャブラリーリスト作成\n",
    "vocab_size = len(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22042\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Okay.', shape=(), dtype=string) tf.Tensor(35, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "i,v = next(iter(train_datasets))\n",
    "print(i,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 775,
     "status": "ok",
     "timestamp": 1600882012519,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "xG69Fps4uBp5"
   },
   "source": [
    "## エンコード(トークンに変換する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1600882012867,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "dreMbGxHuBt8"
   },
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Okay.'\n"
     ]
    }
   ],
   "source": [
    "example_text = next(iter(train_datasets))[0].numpy()\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14576]\n"
     ]
    }
   ],
   "source": [
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1600882013294,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "jqNLp1Mv7fXE"
   },
   "outputs": [],
   "source": [
    "def encode(token, label):\n",
    "    token = encoder.encode(token.numpy())\n",
    "    return token, label\n",
    "\n",
    "@tf.function\n",
    "def tf_encoder(utter, label):\n",
    "    encoded_text, label = tf.py_function(encode,[utter, label],[tf.int64, tf.int32])\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    return encoded_text, label\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "def filter_max_length(x,y,max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_encode = train_datasets.map(tf_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2981], shape=(1,), dtype=int64)\n",
      "tf.Tensor(35, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[  340  1558 13301 20978 17001  8746  1569  8746  1569 21848 20246 20655\n",
      " 20347 14578], shape=(14,), dtype=int64)\n",
      "tf.Tensor(20, shape=(), dtype=int32)\n",
      "tf.Tensor([  782 12244   782 10095  7140   782  7663 11769 10658 21222], shape=(10,), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor([ 4836 13340  5999  2994], shape=(4,), dtype=int64)\n",
      "tf.Tensor(30, shape=(), dtype=int32)\n",
      "tf.Tensor([  782 10095 13340 10685 16518], shape=(5,), dtype=int64)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i,v in all_train_data_encode.take(5):\n",
    "    print(i)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAKE_SIZE = 1000\n",
    "max_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_encode = all_train_data_encode.filter(filter_max_length)\n",
    "\n",
    "## 訓練データ\n",
    "utter_train_data = all_train_data_encode.skip(TAKE_SIZE)\n",
    "utter_train_data = utter_train_data.padded_batch(64, padded_shapes=([max_len], []), drop_remainder=True)\n",
    "\n",
    "## テストデータ\n",
    "utter_test_data = all_train_data_encode.take(TAKE_SIZE)\n",
    "utter_test_data = utter_test_data.padded_batch(64, padded_shapes=([max_len], []), drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PaddedBatchDataset shapes: ((64, 40), (64,)), types: (tf.int64, tf.int32)>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[15731     0     0 ...     0     0     0]\n",
      " [12213 13756     0 ...     0     0     0]\n",
      " [15193   718   782 ...     0     0     0]\n",
      " ...\n",
      " [12213 13756     0 ...     0     0     0]\n",
      " [  155 11266  7052 ...     0     0     0]\n",
      " [12213 13756     0 ...     0     0     0]], shape=(64, 40), dtype=int64)\n",
      "tf.Tensor(\n",
      "[32 40 11 26 26 26 40 26 11 11 11 11 40 26 11 11 40 11 40 11 11 11 26 40\n",
      " 26 26  6 11 11 40 26 40 11 40 11 26 26 26 26 26 40 11 11 11 37 11 11 40\n",
      " 11 11 26 26 40 11 11 11 40 11 38 20 11 40 11 40], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 9226     0     0 ...     0     0     0]\n",
      " [20996 19781     0 ...     0     0     0]\n",
      " [ 4826 11769  2523 ...     0     0     0]\n",
      " ...\n",
      " [  833  3142  8562 ...     0     0     0]\n",
      " [15193 13340 18973 ...     0     0     0]\n",
      " [ 2470 20061 11313 ...     0     0     0]], shape=(64, 40), dtype=int64)\n",
      "tf.Tensor(\n",
      "[40 37 37 40 26 11 40 26 40 20 20 11 26  8 11 11 40 11 26 40 11 11 11 26\n",
      " 40 11 11 40 11 40 11 11 40 35 20 11 40 11 11 11 11 26 37 11 40 11 26 26\n",
      " 37 11 11 11 26 26 26 15 15 26 40 11 26 11 26 11], shape=(64,), dtype=int32)\n"
     ]
    },
    {
     "ename": "DataLossError",
     "evalue": "Attempted to pad to a smaller size than the input element.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2101\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;31m# handles execute on the same device as where the resource is placed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2609\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2611\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: Attempted to pad to a smaller size than the input element. [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-a7fea5dab824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutter_train_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataLossError\u001b[0m: Attempted to pad to a smaller size than the input element."
     ]
    }
   ],
   "source": [
    "for ex,er in utter_train_data.take(5):\n",
    "    print(ex)\n",
    "    print(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1569 15626  4494 ...     0     0     0]\n",
      " [ 6612 14537   782 ...     0     0     0]\n",
      " [  782  2555 21848 ...     0     0     0]\n",
      " ...\n",
      " [  833  7140 12835 ...   560  4494 20814]\n",
      " [ 3363   782 10095 ...     0     0     0]\n",
      " [ 9226     0     0 ...     0     0     0]], shape=(64, 45), dtype=int64)\n",
      "tf.Tensor(\n",
      "[26 37 11 37 40 40 26 26 26 40  6  6 26  6 38 26 26  6 26  6 26 11 11 11\n",
      " 30 11 40 11 40 26 11 11 37 35 11  0 34 37 11 11 40 11 37 11 11 40 11 11\n",
      " 40 20 11 40 11 40 11  8 11 11 11 11 40 26 11 40], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[  833 12313  4356 ...     0     0     0]\n",
      " [12213  1569  6099 ...     0     0     0]\n",
      " [ 9226     0     0 ...     0     0     0]\n",
      " ...\n",
      " [12213 13756     0 ...     0     0     0]\n",
      " [15193  5572  1656 ...     0     0     0]\n",
      " [12213 13756     0 ...     0     0     0]], shape=(64, 41), dtype=int64)\n",
      "tf.Tensor(\n",
      "[11 11 40 26 11 26 11 26  6 11 26 40 26 40 11 11 11 11 11 11 26 40 30  9\n",
      " 18 11 26 26 37 11 32 11 11 11 11 40 11 20 11 10 28 11 11 26 11 40 11 11\n",
      " 40 40 11 11 26 11 40 26 26 20 30 37 11 40 26 40], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 7140  4793   363 ...     0     0     0]\n",
      " [11096     0     0 ...     0     0     0]\n",
      " [  340   782  6099 ...     0     0     0]\n",
      " ...\n",
      " [  782 10095   782 ...     0     0     0]\n",
      " [  833   782 12244 ...     0     0     0]\n",
      " [  208  7140     0 ...     0     0     0]], shape=(64, 37), dtype=int64)\n",
      "tf.Tensor(\n",
      "[26 40 11 11 20 26  0 30 11 26 26 40 26 38 11  6 11 26 11  6 11 11 40 26\n",
      " 20 30 11 11 11 37 26 26  6 11 37 26 26  6 26 26 40 26 37 26 26  6  6 11\n",
      " 11  6 20 26 26  6 26 26 37 40 26 30 37 26 26 37], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[10064     0     0 ...     0     0     0]\n",
      " [  782 10095 12674 ...     0     0     0]\n",
      " [10064     0     0 ...     0     0     0]\n",
      " ...\n",
      " [ 3550     0     0 ...     0     0     0]\n",
      " [13340     0     0 ...     0     0     0]\n",
      " [ 2981     0     0 ...     0     0     0]], shape=(64, 62), dtype=int64)\n",
      "tf.Tensor(\n",
      "[40 26  6  6 26  6 26 37 26 40 11 11 37 11 40 26 26 26 26 40 26 26 40 26\n",
      " 26 30  2 40 26  6  2 40  6 26 26 40 11 40 11 26 26 11 11 40 26 40 38 26\n",
      " 40 26  6 26 40 40 26  6 26  6 26 40 26  6 37 35], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[16961     0     0 ...     0     0     0]\n",
      " [ 3639     0     0 ...     0     0     0]\n",
      " [ 4721  1569 19799 ...     0     0     0]\n",
      " ...\n",
      " [15948 20978     0 ...     0     0     0]\n",
      " [10064     0     0 ...     0     0     0]\n",
      " [15193  2523  1569 ...   560   942  7140]], shape=(64, 18), dtype=int64)\n",
      "tf.Tensor(\n",
      "[21 40 30 36 11 11 40 11 11 11 26 40 11 11 40 11 26 40 37 11 11 40 37 11\n",
      " 26 11  6 37 30 11 40 11 40 11 11 37 11 40 11 40 40 35 11 11 27 40 37 37\n",
      " 37 30  7 11 28 11 40 11 11 37 40  0 36 11 40 11], shape=(64,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for ex,er in utter_train_data.take(5):\n",
    "    print(ex)\n",
    "    print(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Okay.'>, <tf.Tensor: shape=(), dtype=int32, numpy=35>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'So, What kind of experience do you, do you have, then with child care?'>, <tf.Tensor: shape=(), dtype=int32, numpy=20>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'I guess, I think, uh, I wonder if that worked.'>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Does it say something?'>, <tf.Tensor: shape=(), dtype=int32, numpy=30>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'I think it usually does.'>, <tf.Tensor: shape=(), dtype=int32, numpy=11>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'You might try, uh,'>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"I don't know,\">, <tf.Tensor: shape=(), dtype=int32, numpy=38>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'hold it down a little longer,'>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'and see if it, uh,'>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Okay'>, <tf.Tensor: shape=(), dtype=int32, numpy=6>)\n"
     ]
    }
   ],
   "source": [
    "lists_hoge = []\n",
    "for i, ex in enumerate(train_datasets):\n",
    "    if i == 10:\n",
    "        break\n",
    "        \n",
    "    lists_hoge.append(ex)\n",
    "    if i%window_size == 4:\n",
    "        for j in lists_hoge:\n",
    "            print(j)\n",
    "        lists_hoge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size += 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 300),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(41)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 300)         6614100   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 1024)              2500608   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 41)                21033     \n",
      "=================================================================\n",
      "Total params: 9,660,541\n",
      "Trainable params: 9,660,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3031/3031 [==============================] - 2376s 784ms/step - loss: 0.9311 - accuracy: 0.7110 - val_loss: 0.8674 - val_accuracy: 0.7214\n",
      "Epoch 2/3\n",
      "3031/3031 [==============================] - 2252s 743ms/step - loss: 0.7605 - accuracy: 0.7526 - val_loss: 0.8407 - val_accuracy: 0.7380\n",
      "Epoch 3/3\n",
      "3031/3031 [==============================] - 2393s 789ms/step - loss: 0.6785 - accuracy: 0.7751 - val_loss: 0.8931 - val_accuracy: 0.7411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a80114e20>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(utter_train_data, \n",
    "          epochs=3, \n",
    "          validation_data=utter_test_data,\n",
    "          validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1600882666882,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "AJv_mh4S7iOc",
    "outputId": "f94117c5-c70d-438e-dc24-3a7b0c156daa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_data_set = utter_train_dataset.map(tf_encoder)\\ntrain_data_set = train_data_set.filter(filter_max_length)\\ntrain_data_set = train_data_set.cache()\\ntrain_data_set = train_data_set.padded_batch(BATCH_SIZE, padded_shapes=(100,100))\\ntrain_data_set.prefetch(tf.data.experimental.AUTOTUNE)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_data_set = utter_train_dataset.map(tf_encoder)\n",
    "train_data_set = train_data_set.filter(filter_max_length)\n",
    "train_data_set = train_data_set.cache()\n",
    "train_data_set = train_data_set.padded_batch(BATCH_SIZE, padded_shapes=(100,100))\n",
    "train_data_set.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンテキストEncoder層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextEncoder(tf.keras.Model):\n",
    "    def __init__(self, units, batch_size):\n",
    "        super(ContextEncoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.batch_size = batch_size\n",
    "        self.context_gru = tf.keras.layers.GRU(self.units,\n",
    "                                     return_sequences=True,\n",
    "                                     return_state=True,\n",
    "                                     recurrent_activation='sigmoid',\n",
    "                                     recurrent_initializer='glorot_uniform')\n",
    "                                     \n",
    "    def call(self, x, hidden):\n",
    "        output, states = self.gru(x, initial_state=hidden)\n",
    "        return output, states\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### context encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_encoder = ContextEncoder(513, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 発話Encoder層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1329,
     "status": "error",
     "timestamp": 1600882871003,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "e1MRdwVnCGoz",
    "outputId": "801976c1-6112-43e8-b993-7655be6761ea"
   },
   "outputs": [],
   "source": [
    "class UtterEncoder(tf.keras.Model):\n",
    "    def __init__(self, vocabsize, embedding_dim, units, batch_size, output_dim):\n",
    "        super(UtterEncoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.batch_size = batch_size\n",
    "        self.output_dim = output_dim\n",
    "        self.vocabsize = vocabsize\n",
    "        self.embedding = tf.keras.layers.Embedding(vocabsize, embedding_dim)\n",
    "        self.utter_gru = tf.keras.layers.GRU(self.units,\n",
    "                                     return_sequences=True,\n",
    "                                     return_state=True,\n",
    "                                     recurrent_activation='sigmoid',\n",
    "                                     recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tf.keras.layers.Dense(self.units, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(self.output_dim)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, states = self.utter_gru(x, initial_state=hidden)\n",
    "        output = tf.reshape(output,(-1, output.shape[2]))\n",
    "        x = self.fc1(output)\n",
    "        x = self.fc2(x)\n",
    "        return x, states\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 発話エンコーダ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_encoder = UtterEncoder(vocab_size, 300, 512, 64, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22047"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, preds):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(real, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PaddedBatchDataset shapes: ((None, None), (None,)), types: (tf.int64, tf.int32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 2]\n",
    "y_pred = [[0.05, 0.95, 0, 0.08], [0.1, 0.8, 0.1, 1.02], [0.01, 0.10, 1.00, 2.00]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: The shape of labels (received (2,)) should equal the shape of logits except for the last dimension (received (3, 4)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-c17da0eae45a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[1;32m   1564\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m   return K.sparse_categorical_crossentropy(\n\u001b[0m\u001b[1;32m   1567\u001b[0m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[1;32m   1568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4783\u001b[0m           labels=target, logits=output)\n\u001b[1;32m   4784\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4785\u001b[0;31m     res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n\u001b[0m\u001b[1;32m   4786\u001b[0m         labels=target, logits=output)\n\u001b[1;32m   4787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   4173\u001b[0m       \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mequal\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrank\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0mminus\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4174\u001b[0m   \"\"\"\n\u001b[0;32m-> 4175\u001b[0;31m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0m\u001b[1;32m   4176\u001b[0m       labels=labels, logits=logits, name=name)\n\u001b[1;32m   4177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   4086\u001b[0m     if (static_shapes_fully_defined and\n\u001b[1;32m   4087\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n\u001b[0;32m-> 4088\u001b[0;31m       raise ValueError(\"Shape mismatch: The shape of labels (received %s) \"\n\u001b[0m\u001b[1;32m   4089\u001b[0m                        \u001b[0;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4090\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (2,)) should equal the shape of logits except for the last dimension (received (3, 4))."
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFowardNetwork():\n",
    "    def __init__(self, units):\n",
    "        super(FeedFowardNetwork, self).__init__()\n",
    "        self.units = units\n",
    "        self.fc = tf.keras.layers.Dense(self.units)\n",
    "    \n",
    "    def call(self, output):\n",
    "        x = self.fc(output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1600878626943,
     "user": {
      "displayName": "1たかや",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjK7niDwNioltyXR1RE7T_vX2qhrzw_-EUVBIr-=s64",
      "userId": "15317974259866989521"
     },
     "user_tz": -540
    },
    "id": "KmueDuwGzQlB"
   },
   "source": [
    "## 訓練データセット作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hW60niJ8V1Vo"
   },
   "source": [
    "### ウィンドウサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "309gjdNYV1Vv"
   },
   "outputs": [],
   "source": [
    "window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXsLK7QWV1WF"
   },
   "outputs": [],
   "source": [
    "lists_utter_datasets = []\n",
    "for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcFF_DC0V1WK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55gyZ2RWV1WO"
   },
   "source": [
    "### 実行モデル version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09546Plq1kMD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GRU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
