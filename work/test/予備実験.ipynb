{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予備実験"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 発話分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-self-attention\n",
      "  Downloading keras-self-attention-0.47.0.tar.gz (10 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from keras-self-attention) (1.18.5)\n",
      "Collecting Keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.8/site-packages (from Keras->keras-self-attention) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from Keras->keras-self-attention) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.8/site-packages (from Keras->keras-self-attention) (1.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n",
      "Building wheels for collected packages: keras-self-attention\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.47.0-py3-none-any.whl size=17287 sha256=9603916e2614a6a70e19b8da31d5065ad22563b4bf38d3bf7b1ebfadc9241638\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d3/10/ce/49936bed2a8c045ba90f16978392aa37d095aa6b4f5748ed22\n",
      "Successfully built keras-self-attention\n",
      "Installing collected packages: Keras, keras-self-attention\n",
      "Successfully installed Keras-2.4.3 keras-self-attention-0.47.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"../Switchboard-Corpus/swda_data/train_set.txt\"\n",
    "test_dataset_path = \"../Switchboard-Corpus/swda_data/test_set.txt\"\n",
    "val_dataset_path = \"../Switchboard-Corpus/swda_data/val_set.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "f = open(train_dataset_path, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    train_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "f = open(val_dataset_path, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    val_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "f = open(test_dataset_path, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    test_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 訓練データ\n",
    "train_utter_user = []\n",
    "train_utter = []\n",
    "train_utter_label = []\n",
    "\n",
    "## テストデータ\n",
    "test_utter_user = []\n",
    "test_utter = []\n",
    "test_utter_label = []\n",
    "\n",
    "## 検証データ\n",
    "val_utter_user = []\n",
    "val_utter = []\n",
    "val_utter_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "for j in train_dataset:\n",
    "    for i,v in enumerate(j.split(\"|\")):\n",
    "        if i == 0:\n",
    "            train_utter_user.append(v)\n",
    "        elif i==1:\n",
    "            train_utter.append(v)\n",
    "        else:\n",
    "            train_utter_label.append(v)\n",
    "            \n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "for j in test_dataset:\n",
    "    for i,v in enumerate(j.split(\"|\")):\n",
    "        if i == 0:\n",
    "            test_utter_user.append(v)\n",
    "        elif i==1:\n",
    "            test_utter.append(v)\n",
    "        else:\n",
    "            test_utter_label.append(v)\n",
    "            \n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "for j in val_dataset:\n",
    "    for i,v in enumerate(j.split(\"|\")):\n",
    "        if i == 0:\n",
    "            val_utter_user.append(v)\n",
    "        elif i==1:\n",
    "            val_utter.append(v)\n",
    "        else:\n",
    "            val_utter_label.append(v)\n",
    "            \n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベルデータ数値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"../Switchboard-Corpus/swda_data/metadata/labels.txt\"\n",
    "labels = []\n",
    "f = open(label_path, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    labels.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {}\n",
    "for i,v in enumerate(labels):\n",
    "    label[v] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utter_labels = []\n",
    "for i in train_utter_label:\n",
    "    train_utter_labels.append(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_utter_labels = []\n",
    "for i in test_utter_label:\n",
    "    test_utter_labels.append(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_utter_labels = []\n",
    "for i in val_utter_label:\n",
    "    val_utter_labels.append(label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットをtensorflowに扱える形にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((train_utter, train_utter_labels))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_utter, test_utter_labels))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((val_utter, val_utter_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Okay.', shape=(), dtype=string) tf.Tensor(17, shape=(), dtype=int32)\n",
      "tf.Tensor(b'So, What kind of experience do you, do you have, then with child care?', shape=(), dtype=string) tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(b'I guess, I think, uh, I wonder if that worked.', shape=(), dtype=string) tf.Tensor(13, shape=(), dtype=int32)\n",
      "tf.Tensor(b'Does it say something?', shape=(), dtype=string) tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(b'I think it usually does.', shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(b'You might try, uh,', shape=(), dtype=string) tf.Tensor(19, shape=(), dtype=int32)\n",
      "tf.Tensor(b\"I don't know,\", shape=(), dtype=string) tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(b'hold it down a little longer,', shape=(), dtype=string) tf.Tensor(19, shape=(), dtype=int32)\n",
      "tf.Tensor(b'and see if it, uh,', shape=(), dtype=string) tf.Tensor(19, shape=(), dtype=int32)\n",
      "tf.Tensor(b'Okay', shape=(), dtype=string) tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i,v in train_data.take(10):\n",
    "    print(i,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Okay.', shape=(), dtype=string) tf.Tensor(17, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "i,v = next(iter(train_data))\n",
    "print(i,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トークナイザー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ボキャブラリーリスト\n",
    "vocabulary_set = set()\n",
    "## トークナイザー\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "## 分かち書き\n",
    "for text_tensor,_ in train_data:\n",
    "    some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "    vocabulary_set.update(some_tokens)\n",
    "    \n",
    "## ボキャブラリーリスト作成\n",
    "vocab_size = len(vocabulary_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMAX_LENGTH = 40\\ndef filter_max_length(x,y,max_length=MAX_LENGTH):\\n    return tf.logical_and(tf.size(x) <= max_length,\\n                        tf.size(y) <= max_length)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(token, label):\n",
    "    token = encoder.encode(token.numpy())\n",
    "    return token, label\n",
    "\n",
    "@tf.function\n",
    "def tf_encoder(utter, label):\n",
    "    encoded_text, label = tf.py_function(encode,[utter, label],[tf.int64, tf.int32])\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    return encoded_text, label\n",
    "\n",
    "\"\"\"\n",
    "MAX_LENGTH = 40\n",
    "def filter_max_length(x,y,max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "      tf.keras.metrics.Accuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_encode = train_data.map(tf_encoder)\n",
    "all_test_data_encode = test_data.map(tf_encoder)\n",
    "all_val_data_encode = val_data.map(tf_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_train_data = all_train_data_encode.padded_batch(64, padded_shapes=([None], []), drop_remainder=True)\n",
    "utter_test_data = all_test_data_encode.padded_batch(64, padded_shapes=([None], []), drop_remainder=True)\n",
    "utter_val_data = all_val_data_encode.padded_batch(64, padded_shapes=([None], []), drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[13492     0     0 ...     0     0     0]\n",
      " [15216  2228  3140 ...     0     0     0]\n",
      " [20545 16199 20545 ...     0     0     0]\n",
      " ...\n",
      " [ 2971 19685  7800 ...     0     0     0]\n",
      " [ 2343 17762  2098 ...     0     0     0]\n",
      " [  316     0     0 ...     0     0     0]], shape=(64, 21), dtype=int64) tf.Tensor(\n",
      "[17  9 13  6  0 19 12 19 19  4  6  1  0  0  0  2 11  4 10  0  0  0  0  1\n",
      "  6 18 14  7  1  0  3  0  0  1  0  0  1  6  7  0  0  0  0  1  0 14  0  1\n",
      "  0  0  3  0  0  1  0  0  5  5  0  1  0  0  0  1], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2971  8328 17129 ...     0     0     0]\n",
      " [  316     0     0 ...     0     0     0]\n",
      " [ 1987  4163  2983 ...     0     0     0]\n",
      " ...\n",
      " [11682  2343  4561 ...     0     0     0]\n",
      " [ 5486     0     0 ...     0     0     0]\n",
      " [ 8328 19773 13933 ...     0     0     0]], shape=(64, 27), dtype=int64) tf.Tensor(\n",
      "[16  4  0  3  0  6  7  0  1  2  0  4  0  3  2  4  2  1  2  1 13  7  0  1\n",
      " 21  0  0  3  4  2  2  2  1  2 23 17  1  3  0  1  6  6 28  0  1  2  1  6\n",
      "  7  0  0 16  6 35  0  0  1  1  1  2  3  6  3  0], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[14024  2757 19178 ...     0     0     0]\n",
      " [14024 17542 19133 ...     0     0     0]\n",
      " [ 3178    92  9415 ...     0     0     0]\n",
      " ...\n",
      " [21022  5377 21529 ...     0     0     0]\n",
      " [ 3898 17985     0 ...     0     0     0]\n",
      " [14363   990  4683 ...     0     0     0]], shape=(64, 37), dtype=int64) tf.Tensor(\n",
      "[ 0  0  0  0  0  0  3 16 28  0  0  3  3  3  3  6 18  0  0  3 22 10  0  0\n",
      "  1  0  3  2  0  1  0  0  0  1  0  1  0  0  0  0  0  0  1  2  9 24  0  0\n",
      "  0  0  0  2  3  0  0  0  0 12  0  2  0  0 14  0], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 6909 12302 13972 ...     0     0     0]\n",
      " [ 5531 21767 19133 ...     0     0     0]\n",
      " [21022  4794  9858 ...     0     0     0]\n",
      " ...\n",
      " [ 6909 20545 11316 ...     0     0     0]\n",
      " [ 4907  4171     0 ...     0     0     0]\n",
      " [15216 20545 20545 ...     0     0     0]], shape=(64, 31), dtype=int64) tf.Tensor(\n",
      "[ 0  0  0  3  4  3  0  0  0  3  0  0  0  1  2 12  2  2  2  2  1  2  1  2\n",
      "  0  3  0  0  0 12  0  0  2  0  1  0  0  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  1  1  2  0  0  0  2  0 13  7  0  0  0  1  0], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[16190 20545  5521 ...     0     0     0]\n",
      " [ 4907  4171     0 ...     0     0     0]\n",
      " [21022  5377  8328 ...     0     0     0]\n",
      " ...\n",
      " [ 4907  4171     0 ...     0     0     0]\n",
      " [ 2971 20545  7722 ...     0     0     0]\n",
      " [  316     0     0 ...     0     0     0]], shape=(64, 42), dtype=int64) tf.Tensor(\n",
      "[ 0  1  0  2  1  0  0  0  0  0  1 22  0  0  0  1  0  1  2  0  0  0  0  1\n",
      "  0  3  0  5  3  0  0  0  2  1  2  0  1  2  0  3  0  3  5  9  0 11 22  0\n",
      "  0  0  2  1 13 30  0 11  1  0  3  0  2  1  0  1], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 8328  7491  4682 ...     0     0     0]\n",
      " [ 2971   853 20545 ...     0     0     0]\n",
      " [ 4907  4171     0 ...     0     0     0]\n",
      " ...\n",
      " [ 4794 18538 16057 ...     0     0     0]\n",
      " [ 4110  4561 19224 ...     0     0     0]\n",
      " [ 5377  4110  4561 ...     0     0     0]], shape=(64, 27), dtype=int64) tf.Tensor(\n",
      "[ 2  0  1  2  2  1 33  3 22  0  1  0  2  1  0  0  0 17  0  0  0  0  0  0\n",
      "  0  0  2  2  0  0  0  1  0  0  0  5  0  2 12  0  2  0  0  0 15  0  0 15\n",
      " 17  2  4  2  0  0  3  0  2  2  0  0  0  0  0  0], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[17420  4561  1746 ...     0     0     0]\n",
      " [ 3339  2787 13694 ...     0     0     0]\n",
      " [21022 21529  4794 ...     0     0     0]\n",
      " ...\n",
      " [21022  4794 15540 ...     0     0     0]\n",
      " [21022 19133  4794 ...     0     0     0]\n",
      " [21022 11960 16316 ...     0     0     0]], shape=(64, 37), dtype=int64) tf.Tensor(\n",
      "[ 2  2  2  1 23  4  2 22  3  2  3 20  4  0  2  2  0  0  1  2  2  2  0  0\n",
      "  0  0  0  0  0  0  2  0  4  3  6  7  0  1  0  4 23  1  2  1  2  4  2  2\n",
      "  1  2  2  2  2  6 10  0  0  1 21 24  0  0  0  0], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[20545 20106  2747 ...     0     0     0]\n",
      " [ 4794  5817  8328 ...     0     0     0]\n",
      " [21022  4794 14755 ...     0     0     0]\n",
      " ...\n",
      " [15216  8328 17129 ...     0     0     0]\n",
      " [ 9333  2343 16426 ...     0     0     0]\n",
      " [11027     0     0 ...     0     0     0]], shape=(64, 34), dtype=int64) tf.Tensor(\n",
      "[ 0 16  0  0  4 16  4  0  1  0  0  1  0  0  0  0  1  0  0  2  3  0  2  2\n",
      "  1  0  0  1  2  1  2  2  1  0  4  4  0  0  1  0  0  1  0  1  2  1 12  3\n",
      "  2  0  4  2  1 23  1  2  2  1  2  2  1  2  2  4], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[20993     0     0 ...     0     0     0]\n",
      " [15216  8328  8328 ...     0     0     0]\n",
      " [17575 18862 18267 ...     0     0     0]\n",
      " ...\n",
      " [19133 20545  2426 ...     0     0     0]\n",
      " [21529  7808  2881 ...     0     0     0]\n",
      " [16781 17129 17798 ...     0     0     0]], shape=(64, 31), dtype=int64) tf.Tensor(\n",
      "[ 4  2  2  2  2  1  2  2  2  1  2  1  4  0  0  0 17 22  2  3  2  1  0  0\n",
      "  2  4  2  3  2  3  1  2  3  2  4  0  3  2  4 16  4  2  4  2  2  2  1  2\n",
      "  2 27  2  2  4  2 17  2 22  1  2  1 21  0  0  2], shape=(64,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[16781 17129 17085 ...     0     0     0]\n",
      " [21321 19133  1987 ...     0     0     0]\n",
      " [20545  8726  4683 ...     0     0     0]\n",
      " ...\n",
      " [21022 19133  8328 ...     0     0     0]\n",
      " [21022  8328 17129 ...     0     0     0]\n",
      " [21022 19133 20545 ...     0     0     0]], shape=(64, 31), dtype=int64) tf.Tensor(\n",
      "[ 4  0  2  2  1  1  1  0  2  4  3  2  0  2  1  0  1  0  0  1  1  3  2  2\n",
      "  1  2  4 16  4  2  1  0  0  0  1  0  0  0  0  0  0 16  4 16  4 16  0  0\n",
      "  0  5  0  1  0  1  1  2  1  4  0  0  0  0  2  0], shape=(64,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i,v in utter_train_data.take(10):\n",
    "    print(i,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PaddedBatchDataset shapes: ((64, None), (64,)), types: (tf.int64, tf.int32)>,\n",
       " <PaddedBatchDataset shapes: ((64, None), (64,)), types: (tf.int64, tf.int32)>,\n",
       " <PaddedBatchDataset shapes: ((64, None), (64,)), types: (tf.int64, tf.int32)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_train_data, utter_test_data, utter_val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル設計(RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 211s 70ms/step - loss: -171.0589 - accuracy: 0.1976 - val_loss: -309.1272 - val_accuracy: 0.1766\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 216s 72ms/step - loss: -879.7972 - accuracy: 0.1982 - val_loss: -1072.3658 - val_accuracy: 0.1755\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 250s 83ms/step - loss: -2049.8381 - accuracy: 0.1921 - val_loss: -2051.0625 - val_accuracy: 0.1755\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 220s 73ms/step - loss: -3771.5759 - accuracy: 0.1921 - val_loss: -3312.4087 - val_accuracy: 0.1755\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 214s 71ms/step - loss: -5987.7651 - accuracy: 0.1921 - val_loss: -5530.4316 - val_accuracy: 0.1755\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 215s 72ms/step - loss: -8015.5977 - accuracy: 0.1921 - val_loss: -6451.9243 - val_accuracy: 0.1755\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 207s 69ms/step - loss: -10421.9941 - accuracy: 0.1921 - val_loss: -8224.8506 - val_accuracy: 0.1755\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 182s 61ms/step - loss: -13031.8008 - accuracy: 0.1921 - val_loss: -10612.7305 - val_accuracy: 0.1755\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 216s 72ms/step - loss: -17149.3301 - accuracy: 0.1921 - val_loss: -14497.4268 - val_accuracy: 0.1755\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 220s 73ms/step - loss: -22985.5254 - accuracy: 0.1921 - val_loss: -18370.9785 - val_accuracy: 0.1755\n"
     ]
    }
   ],
   "source": [
    "history = rnn_model.fit(utter_train_data, epochs=10,\n",
    "                    validation_data=utter_val_data, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRV9bn/8fdDEgjzFGQIU7AohEkwKld+AkqrtFIRqxWv+lNvxdKKAr2tA7aKrbbWhdV26UXRgkNR60VRy68VQRHaipYgKJMjoAQQAjIIZcjw/P44OyGEhJwNOeyT5PNa66ycs6fznMPwyf7u4TF3R0REJF71oi5ARERqFgWHiIiEouAQEZFQFBwiIhKKgkNEREJJjbqAEyEjI8O7du0adRkiIjXK0qVLt7l7m/LT60RwdO3aldzc3KjLEBGpUczs84qma6hKRERCUXCIiEgoCg4REQmlThzjEJHkUlBQQF5eHvv374+6FAHS09Pp2LEjaWlpcS2v4BCREy4vL4+mTZvStWtXzCzqcuo0d2f79u3k5eWRlZUV1zoaqhKRE27//v20bt1aoZEEzIzWrVuH2vtTcIhIJBQaySPsn4WGqpLUwcJiNuz4N+vy97J++176ZDbnrG6toy5LRETBEaXiYmfTrn2s27aX9dv2snbb3tLnG3bso6j4UK+UpumpvPGTIZzULD3CikVEFBwJ5+5s23OQ9dv3si6/JBz2sH7bv1m/fS8HCotLl22YlkJWRmN6dWjOiL4dyMpoTNeMxqTWMy57bDF3/2U1j1w5IMJPIyJhFBYWkppa+/6brX2fKCK79xewPthjWJsf7DkEYfH1gcLS5dJSjM6tGpGV0ZjBp2SQldGErIzGZGU0pm2zBpWONd583jeY8vrHjFq9hW9mtz1RH0uk1rr44ovZsGED+/fvZ/z48dxwww289tprTJo0iaKiIjIyMnjjjTfYs2cPN910E7m5uZgZd911F9/73vdo0qQJe/bsAWDWrFnMmTOHJ598kmuvvZZWrVqxbNkyBgwYwOWXX86ECRPYt28fDRs2ZMaMGZx66qkUFRVx6623MnfuXMyMMWPGkJ2dzcMPP8zs2bMBmDdvHlOnTuWll16K8qs6goIjhP0FRXy+/d+s27aHtcGQ0rrgsW3PwdLlzCCzRUOyMhozakBmaTBkZTQms0VDUlPCn5Nww+CTefX9Tdz5ykoGntyaJg30Rye1w91/WcXqTburdZvZHZpx13d7HXWZ6dOn06pVK/bt28cZZ5zByJEjGTNmDIsWLSIrK4uvvvoKgF/96lc0b96cFStWALBjx44q3//jjz9m/vz5pKSksHv3bhYtWkRqairz589n0qRJvPjii0ybNo1169axbNkyUlNT+eqrr2jZsiU33ngj+fn5tGnThhkzZnDdddcd/xdSzfS/z1HMX72FhR/nl4bDpl37KNuivU3TBmRlNGZYj7ZktTkUDp1bNSI9LaVaa6mfWo/fXNKXSx99mwde/6jKfxQicnR/+MMfSn+z37BhA9OmTWPw4MGl1zK0atUKgPnz5/P888+XrteyZcsqt33ZZZeRkhL7P2DXrl1cc801fPLJJ5gZBQUFpdsdO3Zs6VBWyftdffXV/OlPf+K6665j8eLFPP3009X0iauPguMo3lm7nZeXb6Rbmyac0bUlWRmdYgHRujFdMxrRND2+qyyry+ldWnLVWV146u31XHxaJv06tTih7y+SCFH8EvTWW28xf/58Fi9eTKNGjRg6dCj9+vXjo48+OmJZd69wCLnstPLXQDRu3Lj0+S9+8QvOPfdcZs+ezfr16xk6dOhRt3vdddfx3e9+l/T0dC677LKkPEai6ziO4pbhPfjgrvN55cZBPDS6P+O/2Z2L+nWgT8fmJzw0Svxs+KlkNGnAbS+toKCouOoVROQIu3btomXLljRq1IgPP/yQd955hwMHDrBw4ULWrVsHUDpUdf755/Pwww+XrlsyVNW2bVvWrFlDcXFx6Z5LZe+VmZkJwJNPPlk6/fzzz+fRRx+lsLDwsPfr0KEDHTp04J577uHaa6+tts9cnRQcR1E/tV7SXaTULD2NX47sxZrNu5n+j3VRlyNSIw0fPpzCwkL69u3LL37xCwYOHEibNm2YNm0al1xyCf369ePyyy8H4Oc//zk7duygd+/e9OvXjwULFgBw3333MWLECM477zzat29f6Xvdcsst3H777QwaNIiioqLS6ddffz2dO3emb9++9OvXj2effbZ03pVXXkmnTp3Izs5O0DdwfMzLDtrXUjk5OV6bGjm5Ozc8s5S/f5LPvIlD6NSqUdQliYSyZs0aevbsGXUZSWvcuHH079+fH/zgByfsPSv6MzGzpe6eU35Z7XHUQGbGL0f2IsWMO15eSV0If5G64vTTT+eDDz7gqquuirqUSik4aqj2zRvyswtOZdHH+bz6/qaoyxGRarJ06VIWLVpEgwYNoi6lUgqOGuzq/+hKv04t+OVfVrPz3werXkFEpBooOGqwlHrGfZf0Yde+An791zVRlyMidYSCo4br2b4ZYwZ344XcPN7+bFvU5YhIHaDgqAXGD+tO51aNuGP2SvYXFFW9gojIcVBw1ALpaSncO6o367bt5ZEFn0ZdjojUcgqOWuKc7m24pH8mjy78jI+3fB11OSK1SpMmTaIuIakoOGqROy7sSZMGqdz+0gqKi3Vth0htU3J7kqgl392z5Ji1btKAOy7M5qf/+z7P/usLrhrYJeqSRKr2t9vgyxXVu812feDb91U6+9Zbb6VLly78+Mc/BmDy5MmYGYsWLWLHjh0UFBRwzz33MHLkyCrfas+ePYwcObLC9Z5++mmmTJmCmdG3b1+eeeYZtmzZwtixY1m7di0AU6dOpUOHDowYMYKVK1cCMGXKFPbs2cPkyZMZOnQoZ599Nv/85z+56KKLOOWUU7jnnns4ePAgrVu3ZubMmbRt27bCviE7d+5k5cqVPPjggwA8/vjjrFmzht/97nfH9fUqOGqZ7w3I5KX38vjt3z7kW9ltaatWsyJHGD16NBMmTCgNjhdeeIHXXnuNiRMn0qxZM7Zt28bAgQO56KKLqrxfXXp6OrNnzz5ivdWrV3Pvvffyz3/+k4yMjNKbGN58880MGTKE2bNnU1RUxJ49e6rs8bFz504WLlwIxG6y+M4772BmPPHEE9x///088MADFfYNqV+/Pn379uX+++8nLS2NGTNm8Nhjjx3v16fgqG3MjF+P6sMFDy3i7r+s4n+uPD3qkkSO7ih7BonSv39/tm7dyqZNm8jPz6dly5a0b9+eiRMnsmjRIurVq8fGjRvZsmUL7dq1O+q23J1JkyYdsd6bb77JpZdeSkZGBnCo38abb75Z2mMjJSWF5s2bVxkcJTdcBMjLy+Pyyy9n8+bNHDx4sLR/SGV9Q8477zzmzJlDz549KSgooE+fPiG/rSPpGEct1DWjMTcP685fV3zJvNVboi5HJCldeumlzJo1iz//+c+MHj2amTNnkp+fz9KlS1m+fDlt27Y9os9GRSpbr7J+GxVJTU2luPhQm4Sj9fe46aabGDduHCtWrOCxxx4rXbay97v++ut58sknq7WboIKjlhpzTjdObduUO19ZyZ4DyXFATSSZjB49mueff55Zs2Zx6aWXsmvXLk466STS0tJYsGABn3/+eVzbqWy9YcOG8cILL7B9+3bgUL+NYcOGMXXqVACKiorYvXs3bdu2ZevWrWzfvp0DBw4wZ86co75fSX+Pp556qnR6ZX1DzjrrLDZs2MCzzz7LFVdcEe/Xc1QKjlqqfmo9fn1JH77cvZ8HXj+yq5lIXderVy++/vprMjMzad++PVdeeSW5ubnk5OQwc+ZMevToEdd2KluvV69e3HHHHQwZMoR+/frxk5/8BIDf//73LFiwgD59+nD66aezatUq0tLSuPPOOznrrLMYMWLEUd978uTJXHbZZZxzzjmlw2BQed8QgO9///sMGjQorra38VA/jlruzldW8sw7nzP7x4M4Ta1mJUmoH8eJNWLECCZOnMiwYcMqXSZp+nGY2XAz+8jMPjWz2yqY38PMFpvZATP7abl5481spZmtMrMJZaZPNrONZrY8eHwnkZ+hpvvZBadyUtMG3K5WsyJ1zs6dOznllFNo2LDhUUMjrISdVWVmKcAjwLeAPGCJmb3q7qvLLPYVcDNwcbl1ewNjgDOBg8BrZvb/3P2TYJEH3X1KomqvTZqmp3H3Rb0Z+6el/PEf6xg75OSoSxKpkVasWMHVV1992LQGDRrw7rvvRlRR1Vq0aMHHH39c7dtN5Om4ZwKfuvtaADN7HhgJlAaHu28FtprZheXW7Qm84+7/DtZdCIwC7k9gvbXW8N7tOD+7LQ/N/5jv9G5P59ZqNSvRC3PWUTLo06cPy5cvj7qMhAh7yCKRQ1WZwIYyr/OCafFYCQw2s9Zm1gj4DtCpzPxxZvaBmU03swqP9pjZDWaWa2a5+fn5x1J/rXL3yF6k1qvHHS+vUKtZiVx6ejrbt2/X38Uk4O5s376d9PT4LxZO5B5HRb9KxPW3xN3XmNlvgXnAHuB9oOSc0qnAr4Jt/Qp4APivCrYxDZgGsYPjYYuvbUpazd716ipeWb6Ji/vHm+Ei1a9jx47k5eWhX+qSQ3p6Oh07dox7+UQGRx6H7yV0BOJuju3ufwT+CGBmvw62h7uXXtFmZo8DlZ/wLIe5amAXZi/byK/mrGbIKW1o2bh+1CVJHZWWllZ6xbPUPIkcqloCdDezLDOrD4wGXo13ZTM7KfjZGbgEeC543b7MYqOIDWtJHFLqGb9Rq1kROU4J2+Nw90IzGwfMBVKA6e6+yszGBvMfNbN2QC7QDCgOTrvNdvfdwItm1hooAG5095KbudxvZqcRG6paD/wwUZ+hNurZvhk3DO7G/7z1GaP6Z3L2NzKqXklEpAxdAFgH7S8o4oKHFlHPjL+NP4f0tJSoSxKRJBTJBYCSnNLTUrj34j5qNSsix0TBUUf9n+4ZXDIgk6lvfcZHX6rVrIjET8FRh/38wmyapqdy+0sfqNWsiMRNwVGHtWpcn59fmM17X+xk5r++iLocEakhFBx13CUDMhn0jdbc/7cP2bK76qY1IiIKjjrOzLj34j4cLCpm8quroi5HRGoABYeUtpr920q1mhWRqik4BIAbBqvVrIjER8EhAKSl1OM334u1mp0yV61mRaRyCg4pNaBzS/7vwC48tXg9yzfsjLocEUlSCg45zE8vOJW2TdO57cUP1GpWRCqk4JDDNE1P4+6Rvfjwy6/54z/WRV2OiCQhBYcc4YJe7bigV6zV7Ofb90ZdjogkGQWHVOjui3qTWq8eP395pdp7ishhFBxSoXbN07ll+Kn8/ZNtvLI87saNIlIHKDikUlee1YX+nVvwyzmr2bH3YNTliEiSUHBIpUpaze7eV8C9ajUrIgEFhxxVj3bN+OGQbsxamsfbn26LuhwRSQIKDqnSTed1p2vrRkyavYL9BUVRlyMiEUuNugBJfulpKdw7qg9XPvEuve+aSz2zqEsSkTg9fk0OQ05pU63bVHBIXAZ9I4OH/7M/qzbtjroUEQmhU8uG1b5NBYfEbUTfDozo2yHqMkQkYjrGISIioSg4REQkFAWHiIiEouAQEZFQFBwiIhKKgkNEREJRcIiISCgKDhERCUXBISIioSg4REQkFAWHiIiEouAQEZFQFBwiIhJKQoPDzIab2Udm9qmZ3VbB/B5mttjMDpjZT8vNG29mK81slZlNKDO9lZnNM7NPgp8tE/kZRETkcAkLDjNLAR4Bvg1kA1eYWXa5xb4CbgamlFu3NzAGOBPoB4wws+7B7NuAN9y9O/BG8FpERE6QRO5xnAl86u5r3f0g8DwwsuwC7r7V3ZcABeXW7Qm84+7/dvdCYCEwKpg3EngqeP4UcHGiPoCIiBwpkcGRCWwo8zovmBaPlcBgM2ttZo2A7wCdgnlt3X0zQPDzpIo2YGY3mFmumeXm5+cf0wcQEZEjJTI4KmpM7fGs6O5rgN8C84DXgPeBwjBv7u7T3D3H3XPatKnefrsiInVZIoMjj0N7CQAdgU3xruzuf3T3Ae4+mNixkE+CWVvMrD1A8HNrNdUrIiJxSGRwLAG6m1mWmdUHRgOvxruymZ0U/OwMXAI8F8x6FbgmeH4N8Eq1VSwiIlVKTdSG3b3QzMYBc4EUYLq7rzKzscH8R82sHZALNAOKg9Nus919N/CimbUmduD8RnffEWz6PuAFM/sB8AVwWaI+g4iIHMnc4zrsUKPl5OR4bm5u1GWIiNQoZrbU3XPKT9eV4yIiEkpcwWFmL5rZhWamoBERqePiDYKpwH8Cn5jZfWbWI4E1iYhIEosrONx9vrtfCQwA1gPzzOxtM7vOzNISWaCIiCSXuIeegjOcrgWuB5YBvycWJPMSUpmIiCSluE7HNbOXgB7AM8B3S275AfzZzHS6kohIHRLvdRwPu/ubFc2o6FQtERGpveIdquppZi1KXphZSzP7cYJqEhGRJBZvcIxx950lL4KruMckpiQREUlm8QZHPTMrvdtt0KSpfmJKEhGRZBbvMY65xO4P9SixW6OPJXa7cxERqWPiDY5bgR8CPyLWZ+N14IlEFSUiIskrruBw92JiV49PTWw5IiKS7OK9jqM78BsgG0gvme7u3RJUl4iIJKl4D47PILa3UQicCzxN7GJAERGpY+INjobu/gax/h2fu/tk4LzElSUiIskq3oPj+4Nbqn8SdPXbCJyUuLJERCRZxbvHMQFoBNwMnA5cxaG+3yIiUodUuccRXOz3fXf/GbAHuC7hVYmISNKqco/D3YuA08teOS4iInVXvMc4lgGvmNn/AntLJrr7SwmpSkREkla8wdEK2M7hZ1I5oOAQEalj4r1yXMc1REQEiP/K8RnE9jAO4+7/Ve0ViYhIUot3qGpOmefpwChgU/WXIyIiyS7eoaoXy742s+eA+QmpSEREklq8FwCW1x3oXJ2FiIhIzRDvMY6vOfwYx5fEenSIiEgdE+9QVdNEFyIiIjVDXENVZjbKzJqXed3CzC5OXFkiIpKs4j3GcZe77yp54e47gbsSU5KIiCSzeIOjouXiPZVXRERqkXiDI9fMfmdmJ5tZNzN7EFiayMJERCQ5xRscNwEHgT8DLwD7gBsTVZSIiCSvuILD3fe6+23unhM8Jrn73qrWM7PhZvaRmX1qZrdVML+HmS02swNm9tNy8yaa2SozW2lmz5lZejB9spltNLPlweM78X5YERE5fvGeVTXPzFqUed3SzOZWsU4K8AjwbSAbuMLMssst9hWxroJTyq2bGUzPcffeQAowuswiD7r7acHjr/F8BhERqR7xDlVlBGdSAeDuO6i65/iZwKfuvtbdDwLPAyPLLuDuW919CVBQwfqpQEMzSyXWtlb3xhIRSQLxBkexmZXeYsTMulLB3XLLyQQ2lHmdF0yrkrtvJLYX8gWwGdjl7q+XWWScmX1gZtPNrGVF2zCzG8ws18xy8/Pz43lbERGJQ7zBcQfwDzN7xsyeARYCt1exTkWtZqsKm9iKsTAYCWQBHYDGZnZVMHsqcDJwGrFQeaCibbj7tJJjMm3atInnbUVEJA7xHhx/DcgBPiJ2ZtV/Ezuz6mjygE5lXnck/uGmbwLr3D3f3QuIdRo8O6hli7sXuXsx8DixITERETlB4r3J4fXAeGL/+S8HBgKLObyVbHlLgO5mlgVsJHZw+z/jrOsLYKCZNSIWUMOA3KCW9u6+OVhuFLAyzm2KiEg1iPfq7/HAGcA77n6umfUA7j7aCu5eaGbjgLnEzoqa7u6rzGxsMP9RM2tHLBCaETuOMgHIdvd3zWwW8B5QCCwDpgWbvt/MTiM27LUe+GH8H1dERI6XuVd92MHMlrj7GWa2HDjL3Q+Y2XJ3Py3xJR6/nJwcz83NjboMEZEaxcyWuntO+enx7nHkBddxvAzMM7Md6PRYEZE6Kd5+HKOCp5PNbAHQHHgtYVWJiEjSCn2HW3dfmIhCRESkZjjWnuMiIlJHKThERCQUBYeIiISi4BARkVAUHCIiEoqCQ0REQlFwiIhIKAoOEREJRcEhIiKhKDhERCQUBYeIiISi4BARkVAUHCIiEoqCQ0REQlFwiIhIKAoOEREJRcEhIiKhKDhERCQUBYeIiISi4BARkVAUHCIiEoqCQ0REQlFwiIhIKAoOEREJRcEhIiKhKDhERCQUBYeIiISi4BARkVAUHCIiEoqCQ0REQlFwiIhIKAoOEREJJaHBYWbDzewjM/vUzG6rYH4PM1tsZgfM7Kfl5k00s1VmttLMnjOz9GB6KzObZ2afBD9bJvIziIjI4RIWHGaWAjwCfBvIBq4ws+xyi30F3AxMKbduZjA9x917AynA6GD2bcAb7t4deCN4LSIiJ0gi9zjOBD5197XufhB4HhhZdgF33+ruS4CCCtZPBRqaWSrQCNgUTB8JPBU8fwq4OBHFi4hIxRIZHJnAhjKv84JpVXL3jcT2Qr4ANgO73P31YHZbd98cLLcZOKmibZjZDWaWa2a5+fn5x/gRRESkvEQGh1UwzeNaMXbcYiSQBXQAGpvZVWHe3N2nuXuOu+e0adMmzKoiInIUiQyOPKBTmdcdOTTcVJVvAuvcPd/dC4CXgLODeVvMrD1A8HNrNdUrIiJxSGRwLAG6m1mWmdUndnD71TjX/QIYaGaNzMyAYcCaYN6rwDXB82uAV6qxZhERqUJqojbs7oVmNg6YS+ysqOnuvsrMxgbzHzWzdkAu0AwoNrMJQLa7v2tms4D3gEJgGTAt2PR9wAtm9gNiAXNZoj6DiIgcydzjOuxQo+Xk5Hhubm7UZYiI1ChmttTdc8pP15XjIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFh4iIhKLgEBGRUBQcIiISioJDRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJBQFx9EUFUZdgYhI0kmNuoCk9tavYfUr0G0odDsXss6B9OZRVyUiEikFx9G07Q1froDlz8GSJ8DqQebpsRA5+VzIzIHU+lFXKSJyQpm7R11DwuXk5Hhubu6xb6DwIOQtgbUL4LMFsOk98GKo3wS6DIqFSLdzoc2pYFZ9hYuIRMjMlrp7zhHTFRzHYN9OWP/3WIisXQBfrY1Nb9r+0LBWt6HQtG31vaeIyAlWWXBoqOpYNGwBPb8bewDs+BzWvhULkY/nwvvPxaaflH1oWKvL2VC/cWQli4hUF+1xVLfiYvjyg1iIrH0LPl8MRQegXhp0OgtOHhoLkw79oV7KialJROQYaKjqRAVHeQX74IvFwbDWW7FQgdjZWVmDDw1rteqm4yMiklQ0VBWVtIZw8nmxB8DebcGwVvBY85fY9BadD4VIt6HQqFUExYqIVE17HFFyh+2fHRrWWrcIDuwGDNr3C87WGgqdBkJaerS1ikido6GqZAyO8ooKYdOyQ6f95v0LigshtWFsj0RDWSIS1oiHoMt/HNOqGqqqCVJSodMZsceQW+DA1/D527G9kd0bo65ORGqi+o2qfZMJDQ4zGw78HkgBnnD3+8rN7wHMAAYAd7j7lGD6qcCfyyzaDbjT3R8ys8nAGCA/mDfJ3f+ayM8RmQZN4ZQLYg8RkSSRsOAwsxTgEeBbQB6wxMxedffVZRb7CrgZuLjsuu7+EXBame1sBGaXWeTBkpAREZETK5F3xz0T+NTd17r7QeB5YGTZBdx9q7svAQqOsp1hwGfu/nniShURkXglMjgygQ1lXucF08IaDTxXbto4M/vAzKabWcuKVjKzG8ws18xy8/PzK1pERESOQSKDo6JTgEKdwmVm9YGLgP8tM3kqcDKxoazNwAMVrevu09w9x91z2rRpE+ZtRUTkKBIZHHlApzKvOwKbQm7j28B77r6lZIK7b3H3IncvBh4nNiQmIiInSCKDYwnQ3cyygj2H0cCrIbdxBeWGqcysfZmXo4CVx1WliIiEkrCzqty90MzGAXOJnY473d1XmdnYYP6jZtYOyAWaAcVmNgHIdvfdZtaI2BlZPyy36fvN7DRiw17rK5gvIiIJpCvHRUSkQnX6liNmlg8c6+m8GcC2aiynptP3cYi+i8Pp+zhcbfg+urj7EWcX1YngOB5mlltR4tZV+j4O0XdxOH0fh6vN30ciD46LiEgtpOAQEZFQFBxVmxZ1AUlG38ch+i4Op+/jcLX2+9AxDhERCUV7HCIiEoqCQ0REQlFwHIWZDTezj8zsUzO7Lep6omJmncxsgZmtMbNVZjY+6pqSgZmlmNkyM5sTdS1RM7MWZjbLzD4M/p4cW6/SWsDMJgb/Tlaa2XNmlh51TdVNwVGJMo2ovg1kA1eYWXa0VUWmEPhvd+8JDARurMPfRVnjgTVRF5Ekfg+85u49gH7U0e/FzDKJNafLcffexG63NDraqqqfgqNyVTaiqivcfbO7vxc8/5rYfwrH0lul1jCzjsCFwBNR1xI1M2sGDAb+CODuB919Z7RVRSoVaGhmqUAjwt8VPOkpOCpXXY2oahUz6wr0B96NtpLIPQTcAhRHXUgS6AbkAzOCobsnzKxx1EVFwd03AlOAL4j1C9rl7q9HW1X1U3BU7rgbUdU2ZtYEeBGY4O67o64nKmY2Atjq7kujriVJpAIDgKnu3h/YC9TJY4JBR9KRQBbQAWhsZldFW1X1U3BUrjoaUdUaZpZGLDRmuvtLUdcTsUHARWa2ntgQ5nlm9qdoS4pUHpDn7iV7obOIBUld9E1gnbvnu3sB8BJwdsQ1VTsFR+WqoxFVrWBmRmz8eo27/y7qeqLm7re7e0d370rs78Wb7l7rfquMl7t/CWwws1ODScOA1RGWFKUvgIFm1ij4dzOMWniiQMIaOdV0lTWiirisqAwCrgZWmNnyYNokd/9rhDVJcrkJmBn8krUWuC7ieiLh7u+a2SzgPWJnIy6jFt56RLccERGRUDRUJSIioSg4REQkFAWHiIiEouAQEZFQFBwiIhKKgkPkOJhZkZktL/Ootiumzayrma2sru2JVBddxyFyfPa5+2lRFyFyImmPQyQBzGy9mRrKtd4AAAGlSURBVP3WzP4VPL4RTO9iZm+Y2QfBz87B9LZmNtvM3g8eJbepSDGzx4P+Dq+bWcNg+ZvNbHWwnecj+phSRyk4RI5Pw3JDVZeXmbfb3c8EHiZ2N12C50+7e19gJvCHYPofgIXu3o/YfZ5K7lLQHXjE3XsBO4HvBdNvA/oH2xmbqA8nUhFdOS5yHMxsj7s3qWD6euA8d18b3CDyS3dvbWbbgPbuXhBM3+zuGWaWD3R09wNlttEVmOfu3YPXtwJp7n6Pmb0G7AFeBl529z0J/qgipbTHIZI4XsnzypapyIEyz4s4dFzyQmIdKk8HlgZNg0ROCAWHSOJcXubn4uD52xxqJXol8I/g+RvAj6C0l3mzyjZqZvWATu6+gFgzqRbAEXs9Iomi31JEjk/DMncMhljf7ZJTchuY2bvEfkG7Iph2MzDdzH5GrGteyV1kxwPTzOwHxPYsfkSsg1xFUoA/mVlzYg3HHqzjrVrlBNMxDpEECI5x5Lj7tqhrEaluGqoSEZFQtMchIiKhaI9DRERCUXCIiEgoCg4REQlFwSEiIqEoOEREJJT/D9dxx36pmVnwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.Input(shape=(None,), batch_size=BATCH_SIZE)\n",
    "embedded = tf.keras.layers.Embedding(encoder.vocab_size, 128)(X)\n",
    "lstm = tf.keras.layers.LSTM(128, dropout=0.4, recurrent_dropout=0.4)(embedded)\n",
    "fully_connected = tf.keras.layers.Dense(units=256, activation='relu')(lstm)\n",
    "Y = tf.keras.layers.Dense(41, activation='sigmoid',name='final_layer')(fully_connected)\n",
    "Rnn_Model = tf.keras.Model(inputs=X, outputs=Y)\n",
    "\n",
    "Rnn_Model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(1e-4),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(64, None)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (64, None, 128)           2797312   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (64, 128)                 131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, 256)                 33024     \n",
      "_________________________________________________________________\n",
      "final_layer (Dense)          (64, 41)                  10537     \n",
      "=================================================================\n",
      "Total params: 2,972,457\n",
      "Trainable params: 2,972,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Rnn_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3006/3006 [==============================] - 444s 148ms/step - loss: 2.1266 - accuracy: 0.3777 - val_loss: 1.8014 - val_accuracy: 0.3859\n",
      "Epoch 2/10\n",
      "3006/3006 [==============================] - 486s 162ms/step - loss: 1.9461 - accuracy: 0.3946 - val_loss: 1.7952 - val_accuracy: 0.4062\n",
      "Epoch 3/10\n",
      "3006/3006 [==============================] - 425s 141ms/step - loss: 1.9068 - accuracy: 0.4023 - val_loss: 1.5573 - val_accuracy: 0.4141\n",
      "Epoch 4/10\n",
      "3006/3006 [==============================] - 14013s 5s/step - loss: 1.6852 - accuracy: 0.4081 - val_loss: 1.4867 - val_accuracy: 0.4156\n",
      "Epoch 5/10\n",
      "3006/3006 [==============================] - 15063s 5s/step - loss: 1.6362 - accuracy: 0.4666 - val_loss: 1.4630 - val_accuracy: 0.5380\n",
      "Epoch 6/10\n",
      "3006/3006 [==============================] - 441s 147ms/step - loss: 1.5806 - accuracy: 0.5561 - val_loss: 1.3935 - val_accuracy: 0.5432\n",
      "Epoch 7/10\n",
      "3006/3006 [==============================] - 3094s 1s/step - loss: 1.4212 - accuracy: 0.5670 - val_loss: 1.2036 - val_accuracy: 0.5688\n",
      "Epoch 8/10\n",
      "3006/3006 [==============================] - 2525s 840ms/step - loss: 1.3207 - accuracy: 0.5791 - val_loss: 1.1606 - val_accuracy: 0.5667\n",
      "Epoch 9/10\n",
      "3006/3006 [==============================] - 387s 129ms/step - loss: 1.2705 - accuracy: 0.5790 - val_loss: 1.1257 - val_accuracy: 0.5708\n",
      "Epoch 10/10\n",
      "3006/3006 [==============================] - 420s 140ms/step - loss: 1.2294 - accuracy: 0.6238 - val_loss: 1.0829 - val_accuracy: 0.6812\n"
     ]
    }
   ],
   "source": [
    "history = Rnn_Model.fit(utter_train_data, epochs=10,\n",
    "                    validation_data=utter_val_data, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル(Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.Input(shape=(None,), batch_size=BATCH_SIZE)\n",
    "embedded = tf.keras.layers.Embedding(encoder.vocab_size, 64)(X)\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,return_sequences=True,return_state=True, dropout=0.4, recurrent_dropout=0.4))(embedded)\n",
    "state_h = tf.keras.layers.Concatenate()([forward_h, backward_h]) # 重みを結合\n",
    "context,attention_weights = Attention(64)(lstm,state_h) # ここにAttentionレイヤを挟む\n",
    "fully_connected = tf.keras.layers.Dense(units=128, activation='relu')(context)\n",
    "Y = tf.keras.layers.Dense(41, activation='sigmoid',name='final_layer')(fully_connected)\n",
    "\n",
    "Attention_Model = tf.keras.Model(inputs=X, outputs=Y)\n",
    "\n",
    "Attention_Model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(64, None)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (64, None, 64)       1398656     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) [(64, None, 256), (N 197632      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256)          0           bidirectional_4[0][1]            \n",
      "                                                                 bidirectional_4[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         ((64, 256), (64, Non 32961       bidirectional_4[0][0]            \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (64, 128)            32896       attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "final_layer (Dense)             (64, 41)             5289        dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,667,434\n",
      "Trainable params: 1,667,434\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Attention_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:748 train_step\n        loss = self.compiled_loss(\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (64, 1) and (64, 41) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-9ff3c8657c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m Attention_Model.fit(utter_train_data, epochs=1,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutter_val_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     validation_steps=30)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:748 train_step\n        loss = self.compiled_loss(\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (64, 1) and (64, 41) are incompatible\n"
     ]
    }
   ],
   "source": [
    "Attention_Model.fit(utter_train_data, epochs=1,\n",
    "                    validation_data=utter_val_data, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4 = Attention_Model.layers[4]\n",
    "len(l4.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntf.keras.utils.plot_model(Attention_Model, show_shapes=True, show_layer_names=True, to_file='model.png')\\nfrom IPython.display import Image\\nImage(retina=False, filename='model.png')\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tf.keras.utils.plot_model(Attention_Model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "from IPython.display import Image\n",
    "Image(retina=False, filename='model.png')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[13492     0     0 ...     0     0     0]\n",
      " [15216  2228  3140 ...     0     0     0]\n",
      " [20545 16199 20545 ...     0     0     0]\n",
      " ...\n",
      " [ 2971 19685  7800 ...     0     0     0]\n",
      " [ 2343 17762  2098 ...     0     0     0]\n",
      " [  316     0     0 ...     0     0     0]], shape=(64, 21), dtype=int64) tf.Tensor(\n",
      "[17  9 13  6  0 19 12 19 19  4  6  1  0  0  0  2 11  4 10  0  0  0  0  1\n",
      "  6 18 14  7  1  0  3  0  0  1  0  0  1  6  7  0  0  0  0  1  0 14  0  1\n",
      "  0  0  3  0  0  1  0  0  5  5  0  1  0  0  0  1], shape=(64,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "i,v = next(iter(utter_train_data.take(1)))\n",
    "print(i,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (64, None) for input Tensor(\"input_4:0\", shape=(64, None), dtype=float32), but it was called on an input with incompatible shape (32, 21).\n"
     ]
    }
   ],
   "source": [
    "predict = Attention_Model.predict(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
