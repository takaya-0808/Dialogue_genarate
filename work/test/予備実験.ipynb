{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予備実験"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 発話分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"../Switchboard-Corpus/swda_data/train_set.txt\"\n",
    "test_dataset_path = \"../Switchboard-Corpus/swda_data/test_set.txt\"\n",
    "val_dataset_path = \"../Switchboard-Corpus/swda_data/val_set.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "f = open(train_dataset_path, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    train_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "f = open(val_dataset_path, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    val_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "f = open(test_dataset_path, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    test_dataset.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 訓練データ\n",
    "train_utter_user = []\n",
    "train_utter = []\n",
    "train_utter_label = []\n",
    "\n",
    "## テストデータ\n",
    "test_utter_user = []\n",
    "test_utter = []\n",
    "test_utter_label = []\n",
    "\n",
    "## 検証データ\n",
    "val_utter_user = []\n",
    "val_utter = []\n",
    "val_utter_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "for j in train_dataset:\n",
    "    for i,v in enumerate(j.split(\"|\")):\n",
    "        if i == 0:\n",
    "            train_utter_user.append(v)\n",
    "        elif i==1:\n",
    "            train_utter.append(v)\n",
    "        else:\n",
    "            train_utter_label.append(v)\n",
    "            \n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "for j in test_dataset:\n",
    "    for i,v in enumerate(j.split(\"|\")):\n",
    "        if i == 0:\n",
    "            test_utter_user.append(v)\n",
    "        elif i==1:\n",
    "            test_utter.append(v)\n",
    "        else:\n",
    "            test_utter_label.append(v)\n",
    "            \n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "for j in val_dataset:\n",
    "    for i,v in enumerate(j.split(\"|\")):\n",
    "        if i == 0:\n",
    "            val_utter_user.append(v)\n",
    "        elif i==1:\n",
    "            val_utter.append(v)\n",
    "        else:\n",
    "            val_utter_label.append(v)\n",
    "            \n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベルデータ数値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"../Switchboard-Corpus/swda_data/metadata/labels.txt\"\n",
    "labels = []\n",
    "f = open(label_path, \"r\", encoding='utf-8')\n",
    "for row in f:\n",
    "    labels.append(row.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {}\n",
    "for i,v in enumerate(labels):\n",
    "    label[v] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_utter_labels = []\n",
    "for i in train_utter_label:\n",
    "    train_utter_labels.append(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_utter_labels = []\n",
    "for i in test_utter_label:\n",
    "    test_utter_labels.append(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_utter_labels = []\n",
    "for i in val_utter_label:\n",
    "    val_utter_labels.append(label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットをtensorflowに扱える形にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((train_utter, train_utter_labels))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_utter, test_utter_labels))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((val_utter, val_utter_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Okay.', shape=(), dtype=string) tf.Tensor(17, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "i,v = next(iter(train_data))\n",
    "print(i,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トークナイザー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ボキャブラリーリスト\n",
    "vocabulary_set = set()\n",
    "## トークナイザー\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "## 分かち書き\n",
    "for text_tensor,_ in train_data:\n",
    "    some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "    vocabulary_set.update(some_tokens)\n",
    "    \n",
    "## ボキャブラリーリスト作成\n",
    "vocab_size = len(vocabulary_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_code = tfds.features.text.TokenTextEncoder(vocabulary_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMAX_LENGTH = 40\\ndef filter_max_length(x,y,max_length=MAX_LENGTH):\\n    return tf.logical_and(tf.size(x) <= max_length,\\n                        tf.size(y) <= max_length)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(token, label):\n",
    "    token = en_code.encode(token.numpy())\n",
    "    return token, label\n",
    "\n",
    "@tf.function\n",
    "def tf_encoder(utter, label):\n",
    "    encoded_text, label = tf.py_function(encode,[utter, label],[tf.int64, tf.int32])\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    return encoded_text, label\n",
    "\n",
    "\"\"\"\n",
    "MAX_LENGTH = 40\n",
    "def filter_max_length(x,y,max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data_encode = train_data.map(tf_encoder)\n",
    "all_test_data_encode = test_data.map(tf_encoder)\n",
    "all_val_data_encode = val_data.map(tf_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "utter_train_data = all_train_data_encode.padded_batch(64, padded_shapes=([max_len], []), drop_remainder=True)\n",
    "utter_test_data = all_test_data_encode.padded_batch(64, padded_shapes=([max_len], []), drop_remainder=True)\n",
    "utter_val_data = all_val_data_encode.padded_batch(64, padded_shapes=([max_len], []), drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PaddedBatchDataset shapes: ((64, 40), (64,)), types: (tf.int64, tf.int32)>,\n",
       " <PaddedBatchDataset shapes: ((64, 40), (64,)), types: (tf.int64, tf.int32)>,\n",
       " <PaddedBatchDataset shapes: ((64, 40), (64,)), types: (tf.int64, tf.int32)>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utter_train_data, utter_test_data, utter_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
